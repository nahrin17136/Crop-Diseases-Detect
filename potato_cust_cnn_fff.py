# -*- coding: utf-8 -*-
"""potato-cust-cnn-fff.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JA1-oOrbej6PwyETUxKAuizpeeca_bGW

# Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import tensorflow as tf
import cv2
from keras import backend as K
from keras.layers import Layer,InputSpec
import keras.layers as kl
from glob import glob
from sklearn.metrics import roc_curve, auc
from keras.preprocessing import image
from tensorflow.keras.models import Sequential
from sklearn.metrics import roc_auc_score
from tensorflow.keras import callbacks
from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping
from  matplotlib import pyplot as plt
from tensorflow.keras import Model
from tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout
# %matplotlib inline
import shutil
from sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix
from tensorflow.python.platform import build_info as tf_build_info
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

train_path = '/kaggle/input/splitted-corps-diseases/Splitted/splitted_Potato/train'
test_path = '/kaggle/input/splitted-corps-diseases/Splitted/splitted_Potato/test'
val_path = '/kaggle/input/splitted-corps-diseases/Splitted/splitted_Potato/val'

targetnames = ['PEB', 'PH', 'PLB']
num_classes = 3
image_size = 224
batch_size = 16

"""## Dataset generation (Train, Test, Validation)"""

# Creating Image Data Generator for train
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255.0
    )

# Creating Image Data Generator for test set
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255.0
    )

# Creating Image Data Generator for val set
val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255.0
    )

print("\nTrain Batches: ")
train_batches = train_datagen.flow_from_directory(directory=train_path,
                                            target_size=(image_size,image_size),
                                            batch_size=batch_size,
                                            shuffle=True)

print("\nTest Batches: ")
test_batches = test_datagen.flow_from_directory(test_path,
                                          target_size=(image_size,image_size),
                                          batch_size=batch_size,
                                          shuffle=False)
print("\nVal Batches: ")
val_batches = val_datagen.flow_from_directory(val_path,
                                         target_size=(image_size,image_size),
                                         batch_size=batch_size,
                                         shuffle=False)

train_batches.class_indices

"""# Custom Model Creation"""

# Define the model architecture
model = Sequential([
    Conv2D(32, (3,3), strides=(1,1), padding='same', activation='relu', input_shape=(image_size, image_size, 3)),
    MaxPooling2D((2,2)),
    BatchNormalization(),
    Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu'),
    MaxPooling2D((2,2)),
    BatchNormalization(),
    Conv2D(128, (5,5), strides=(1,1), padding='same', activation='relu'),
    MaxPooling2D((2,2)),
    BatchNormalization(),
    Conv2D(256, (7,7), strides=(1,1), padding='same', activation='relu'),
    MaxPooling2D((2,2)),
    BatchNormalization(),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    BatchNormalization(),
    Dense(32, activation='relu'),
    Dropout(0.3),
    BatchNormalization(),
    Dense(3, activation='softmax')
])

model.summary()

num_classes = train_batches.num_classes
print("Number of classes: ", num_classes)

opt1 = tf.keras.optimizers.Adam(learning_rate = 0.0001,epsilon = 0.1)
model.compile(optimizer = opt1,
             loss = 'categorical_crossentropy',
             metrics = ['accuracy'])

checkpoint1 = ModelCheckpoint(filepath = 'irv2SA.hdf5', monitor = 'val_accuracy', save_best_only = True, save_weights_only = True)
Earlystop = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 15, min_delta = 0.0001)
epoch = 40

history1 = model.fit(train_batches,
                      epochs = epoch,
                      verbose = 2,
                      validation_data = val_batches,
                      callbacks = [checkpoint1,Earlystop])

"""## History plotting"""

epochs = [i for i in range(epoch)]
fig , ax = plt.subplots(1,2)
train_acc = history1.history['accuracy']
train_loss = history1.history['loss']
val_acc = history1.history['val_accuracy']
val_loss = history1.history['val_loss']
fig.set_size_inches(15,5)

ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')
ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')
title_font = {'fontname':'Times New Roman', 'size':'14', 'color':'black', 'weight':'normal'}
ax[0].set_title('Model Accuracy', fontdict=title_font)
legend_font = {'family': 'Times New Roman', 'size': '12', 'weight': 'normal'}
ax[0].legend(prop=legend_font)
label_font = {'fontname':'Times New Roman', 'size':'12', 'color':'black', 'weight':'normal'}
ax[0].set_xlabel("Epochs",  fontdict=label_font)
ax[0].set_ylabel("Accuracy",  fontdict=label_font)

ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')
ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')
ax[1].set_title('Model Loss', fontdict=title_font)
ax[1].legend(prop=legend_font)
ax[1].set_xlabel("Epochs", fontdict=label_font)
ax[1].set_ylabel("Loss", fontdict=label_font)
plt.show()

from tensorflow.keras import models
model.load_weights("irv2SA.hdf5")

predictions1 = model.predict(test_batches)

"""## Creating classification report"""

#geting predictions on test dataset
y_pred = np.argmax(predictions1, axis=1)
#getting the true labels per image
y_true = test_batches.classes
#getting the predicted labels per image
y_prob = predictions1
from tensorflow.keras.utils import to_categorical
y_test = to_categorical(y_true)

report = classification_report(y_true, y_pred, target_names=targetnames)

print("\nClassification Report:")
print(report)

"""## Results"""

test_loss, test_accuracy = model.evaluate(test_batches)
print("Test Accuracy:", test_accuracy)
print("Test Loss:", test_loss)

"""## Confusion Matrix"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
# Creating confusion matrix
cm = confusion_matrix(y_true, y_pred)
# Plotting the confusion matrix
plt.figure(figsize=(5,2.8))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=targetnames, yticklabels=targetnames)
plt.xlabel('Predicted Label', fontdict=label_font)
plt.ylabel('True Label', fontdict=label_font)
plt.title('Confusion Matrix', fontdict=title_font)
plt.show()

"""### Individual Class Accuracy"""

# y_true are the true labels of the test set
# y_pred are the predicted labels of the test set
accuracy = accuracy_score(y_true, y_pred)
# Calculate accuracy for each class
class_accuracy = cm.diagonal()/cm.sum(axis=1)
print("Overall accuracy: {:.2f}%".format(accuracy*100))
print("Accuracy for each class:")
for i, acc in enumerate(class_accuracy):
    print("Class {}: {:.2f}%".format(i, acc*100))

"""### Individual Class Weighted Precision"""

report = classification_report(y_true, y_pred, output_dict=True)
# Extract weighted precision for each class
class_precision = {}
for class_label in report.keys():
    if class_label == 'weighted avg':
        class_precision['weighted'] = report[class_label]['precision']
    elif class_label.isdigit():
        class_precision[int(class_label)] = report[class_label]['precision']
print("Weighted precision for each class:")
for i, precision in class_precision.items():
    if i == 'weighted':
        print("Weighted precision: {:.2f}%".format(precision*100))
    else:
        print("Class {}: {:.2f}%".format(i, precision*100))

"""### Individual Class Weighted Recall"""

report = classification_report(y_true, y_pred, output_dict=True)
# Extract weighted recall for each class
class_recall = {}
for class_label in report.keys():
    if class_label == 'weighted avg':
        class_recall['weighted'] = report[class_label]['recall']
    elif class_label.isdigit():
        class_recall[int(class_label)] = report[class_label]['recall']
print("Weighted recall for each class:")
for i, recall in class_recall.items():
    if i == 'weighted':
        print("Weighted Recall: {:.2f}%".format(recall*100))
    else:
        print("Class {}: {:.2f}%".format(i, recall*100))

"""### Individual Class Weighted F1-score"""

report = classification_report(y_true, y_pred, output_dict=True)
# Extract weighted F1-score for each class
class_f1 = {}
for class_label in report.keys():
    if class_label == 'weighted avg':
        class_f1['weighted'] = report[class_label]['f1-score']
    elif class_label.isdigit():
        class_f1[int(class_label)] = report[class_label]['f1-score']
print("Weighted F1-score for each class:")
for i, f1_score in class_f1.items():
    if i == 'weighted':
        print("Weighted F1-score: {:.2f}%".format(f1_score*100))
    else:
        print("Class {}: {:.2f}%".format(i, f1_score*100))

"""### Individual Class Precision, Recall and F1-score"""

from sklearn.metrics import precision_recall_fscore_support

precision_class, recall_class, f1_class, support_class = precision_recall_fscore_support(y_true, y_pred, average=None)
print('Class-wise weighted precision, recall, and F1-score:')
for i in range(len(precision_class)):
    print('Class {}: Precision={:.2f}, Recall={:.2f}, F1-score={:.2f}'.format(i, precision_class[i], recall_class[i], f1_class[i]))

"""### Individual Class Weighted Sensitivity"""

from imblearn.metrics import sensitivity_score

sensitivity = sensitivity_score(y_true, y_pred, average='weighted')
print("Weighted Sensitivity: ", sensitivity)

# Calculate class-wise sensitivity
sensitivity = sensitivity_score(y_true, y_pred, average=None)

# Print sensitivity score for each class
for i in range(len(sensitivity)):
    print("Class ", i, ":sensitivity =", sensitivity[i])

"""### Individual Class Weighted Specificity"""

from imblearn.metrics import specificity_score

specificity = specificity_score(y_true, y_pred, average='weighted')
print("Weighted Specificity: ", specificity)

# Calculate class-wise specificity
specificity = specificity_score(y_true, y_pred, average=None)

# Print sensitivity score for each class
for i in range(len(specificity)):
    print("Class ", i, ":specificity=", specificity[i])

"""### Accuracy"""

print("Accuracy: " + str(accuracy_score(y_true, y_pred)))

"""### Weighted Evaluation Measures"""

from sklearn.metrics import f1_score
print("Weighted Precision: "+ str(precision_score(y_true, y_pred, average='weighted')))
print("Weighted Recall: "+ str(recall_score(y_true, y_pred, average='weighted')))
f1 = f1_score(y_true, y_pred, average='weighted')
print("Weighted F1-Score: " + str(f1))
print("Weighted Sensitivity: "+ str(sensitivity_score(y_true, y_pred, average='weighted')))
print("Weighted Specificity: "+ str(specificity_score(y_true, y_pred, average='weighted')))
print("Weighted Roc score: " + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='weighted')))

"""### Macro Evaluation Measures"""

print("Macro Precision: "+ str(precision_score(y_true, y_pred, average='macro')))
print("Macro Recall: "+ str(recall_score(y_true, y_pred, average='macro')))
print("Macro F1-Score: "+ str(f1_score(y_true, y_pred, average='macro')))
print("Macro Sensitivity: "+ str(sensitivity_score(y_true, y_pred, average='macro')))
print("Macro Specificity: "+ str(specificity_score(y_true, y_pred, average='macro')))
print("Macro Roc score: " + str(roc_auc_score(y_true,y_prob,multi_class='ovr',average='macro')))

"""### Micro Evaluation Measures"""

print("Micro Precision: "+ str(precision_score(y_true, y_pred, average='micro')))
print("Micro Recall: "+ str(recall_score(y_true, y_pred, average='micro')))
print("Micro F1-Score: "+ str(f1_score(y_true, y_pred, average='micro')))
print("Micro Sensitivity: "+ str(sensitivity_score(y_true, y_pred, average='micro')))
print("Micro Specificity: "+ str(specificity_score(y_true, y_pred, average='micro')))

"""## ROC

### Individual Class Wise ROC AUC
"""

fpr = {}
tpr = {}
roc_auc = {}
for i in range(num_classes):
    r = roc_auc_score(y_test[:, i], y_prob[:, i])
    print("The ROC AUC score of "+targetnames[i]+" is: "+str(r))

# Compute ROC curve and ROC area for each class
fpr = {}
tpr = {}
roc_auc = dict()
for i in range(3):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(4.5, 2.8))
plt.plot(fpr[0], tpr[0],'r',label='PEB ROC area = %0.4f)' % roc_auc[0])
plt.plot(fpr[1], tpr[1],'y',label='PH ROC area = %0.4f)' % roc_auc[1])
plt.plot(fpr[2], tpr[2],'b',label='PLB ROC area = %0.4f)' % roc_auc[2])
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([-0.1, 1.1])
plt.ylim([-0.1, 1.1])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUROC curve')
plt.legend(loc="lower right")
plt.show()

"""### Compute ROC curve and ROC area for each class"""

fpr = {}
tpr = {}
roc_auc = dict()
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_prob[:, i], drop_intermediate=False)
    roc_auc[i] = auc(fpr[i], tpr[i])


# plot the ROC curve for each class
for i in range(3):
    plt.plot(fpr[i], tpr[i], label='Class {}: AUC={:.4f}'.format(i, roc_auc[i]))

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

"""## MCC and Kappa Score"""

from sklearn.metrics import matthews_corrcoef, cohen_kappa_score

# y_true are the true labels of the test set
# y_pred are the predicted labels of the test set
mcc = matthews_corrcoef(y_true, y_pred)
kappa = cohen_kappa_score(y_true, y_pred)
print("MCC: {:.2f}%".format(mcc*100))
print("Kappa Score: {:.2f}%".format(kappa*100))

"""### Individual Class Wise MCC and Kappa"""

from sklearn.metrics import confusion_matrix, matthews_corrcoef, cohen_kappa_score
# y_true are the true labels of the test set
# y_pred are the predicted labels of the test set
conf_mat = confusion_matrix(y_true, y_pred)
mcc_per_class = {}
kappa_per_class = {}

for i in range(len(conf_mat)):
    tp = conf_mat[i][i]
    fp = sum(conf_mat[:, i]) - tp
    fn = sum(conf_mat[i, :]) - tp
    tn = sum(sum(conf_mat)) - tp - fp - fn

    mcc_per_class[i] = matthews_corrcoef([1 if x==i else 0 for x in y_true], [1 if x==i else 0 for x in y_pred])
    kappa_per_class[i] = cohen_kappa_score([1 if x==i else 0 for x in y_true], [1 if x==i else 0 for x in y_pred])

print("MCC per class:")
for i, mcc in mcc_per_class.items():
    print("Class {}: {:.2f}%".format(i, mcc*100))

print("Kappa Score per class:")
for i, kappa in kappa_per_class.items():
    print("Class {}: {:.2f}%".format(i, kappa*100))

"""# Gradient Class Activation Map"""

# Display
from IPython.display import Image, display
import matplotlib.pyplot as plt
import matplotlib.cm as cm

test_batches = test_datagen.flow_from_directory(test_path,
                                          target_size=(image_size,image_size),
                                          batch_size=batch_size,
                                          shuffle=False)

img_size = (224, 224)

img_array,_=next(test_batches)
last_conv_layer_name = "conv2d_3"

plt.imshow((img_array[0]+1)/2)

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

preds = model.predict(img_array)
np.argmax(preds)

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)

plt.imshow(heatmap)

def save_and_display_gradcam(img_array, heatmap, alpha=0.4):
    # Load the original image

    img = (img_array[0] + 1)/2

    # Rescale heatmap to a range 0-255
    #heatmap = np.uint8(255 * heatmap)
    plt.imshow(img,alpha=1.0)
    plt.imshow(cv2.resize(heatmap,(299,299)),cmap='jet',alpha=0.8)
    plt.show()

    # Display Grad CAM



save_and_display_gradcam(img_array, heatmap)

plt.imshow((img_array[0]+1)/2)

def save_and_display_gradcam(img_array, heatmap, alpha=0.4):
    # Load the original image

    img = (img_array[0] + 1)/2

    # Rescale heatmap to a range 0-255
    #heatmap = np.uint8(255 * heatmap)
    plt.imshow(img,alpha=1.0)
    plt.imshow(cv2.resize(heatmap,(299,299)),cmap='jet',alpha=0.8)
    plt.show()

# Display Grad CAM
save_and_display_gradcam(img_array, heatmap)

# Display
from IPython.display import Image, display
import matplotlib.pyplot as plt
import matplotlib.cm as cm

test_batches = test_datagen.flow_from_directory(test_path,
                                          target_size=(image_size,image_size),
                                          batch_size=batch_size,
                                          shuffle=False)

img_size = (224, 224)

img_array,_=next(test_batches)
last_conv_layer_name = "conv2d"

plt.imshow((img_array[0]+1)/2)

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

preds = model.predict(img_array)
np.argmax(preds)

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)

plt.imshow(heatmap)

plt.imshow(heatmap)

def save_and_display_gradcam(img_array, heatmap, alpha=0.4):
    # Load the original image

    img = (img_array[0] + 1)/2

    # Rescale heatmap to a range 0-255
    #heatmap = np.uint8(255 * heatmap)
    plt.imshow(img,alpha=1.0)
    plt.imshow(cv2.resize(heatmap,(299,299)),cmap='jet',alpha=0.8)
    plt.show()

    # Display Grad CAM



save_and_display_gradcam(img_array, heatmap)

"""# conv2d_1"""

def save_and_display_gradcam(img_array, heatmap, alpha=0.4):
    # Load the original image

    img = (img_array[0] + 1)/2

    # Rescale heatmap to a range 0-255
    #heatmap = np.uint8(255 * heatmap)
    plt.imshow(img,alpha=1.0)
    plt.imshow(cv2.resize(heatmap,(299,299)),cmap='jet',alpha=0.8)
    plt.show()

    # Display Grad CAM



save_and_display_gradcam(img_array, heatmap)

"""# after conv2d_2"""

plt.imshow(heatmap)

def save_and_display_gradcam(img_array, heatmap, alpha=0.4):
    # Load the original image

    img = (img_array[0] + 1)/2

    # Rescale heatmap to a range 0-255
    #heatmap = np.uint8(255 * heatmap)
    plt.imshow(img,alpha=1.0)
    plt.imshow(cv2.resize(heatmap,(299,299)),cmap='jet',alpha=0.8)
    plt.show()

    # Display Grad CAM



save_and_display_gradcam(img_array, heatmap)

"""# Soft Attention Region"""

sa_model = Model(model.inputs,model.get_layer('soft_attention').output)
sa_features, sa_maps = sa_model.predict(x_test)
sa_maps.shape

img_idx = 5
t = (x_test + 1)/2 # bring the range between 0,1 from -1,1
plt.imshow(t[img_idx])

sum_attnmap = np.sum(sa_maps[img_idx],0)
sum_attnmap.shape

plt.imshow(t[img_idx],alpha=1.0)
plt.imshow(cv2.resize(sum_attnmap,(299,299),interpolation=cv2.INTER_CUBIC),cmap='jet',alpha=0.5)
plt.show()